Colpali-Based Multimodal RAG Application

A professional, streamlined setup for running a Colpali-based Retrieval-Augmented Generation (RAG) application on your local machine. This application indexes PDF documents, stores them for quick access, and uses an LLM (e.g., OpenAI) to answer queries about the indexed content.

1. Repository Overview
	•	app.py: Main Streamlit application script.
	•	doc/: Folder where uploaded or existing PDF documents are stored for indexing.
	•	.env: Environment variables file (e.g., for API keys).
	•	requirements.txt: Dependencies needed for the project.
	•	venv/ (optional): Virtual environment directory, if you choose to create it within the project folder.

2. Prerequisites
	1.	Python 3.8+
	2.	pip (Included by default with most Python installations)
	3.	OpenAI API Key (Required for the LLM functionality)

3. Environment Configuration

Create a .env file in the project’s root directory with at least:

OPENAI_API_KEY=your-openai-api-key

	Note:
		•	Keep your .env file out of version control if your repo is public.
	•	Additional environment variables can be added to .env as needed.

4. Virtual Environment Setup

It is highly recommended to use a virtual environment to avoid conflicts with other Python projects:
	1.	Create a virtual environment (e.g., venv):

python -m venv venv


	2.	Activate the virtual environment:
	•	macOS/Linux:

source venv/bin/activate


	•	Windows (PowerShell):

.\venv\Scripts\activate

5. Installation

While in your activated virtual environment:
	1.	Update pip (optional but recommended):

pip install --upgrade pip


	2.	Install required packages:

pip install -r requirements.txt



Your requirements.txt should include (at minimum):

streamlit
byaldi        # or colpali, depending on your library version
openai
python-dotenv
torch
pillow
requests
...

6. Project Structure & Document Handling
	1.	PDF Storage:
	•	Make sure your doc/ folder exists in the project root.
	•	When you upload a PDF in the Streamlit app, it will be saved automatically to doc/.
	2.	Indexing:
	•	The application automatically indexes newly uploaded PDFs.
	•	If you already have PDFs in the doc/ folder (manually placed there), you’ll need to modify the indexing logic in app.py to handle them (if required).
	3.	Selecting a Document:
	•	In the Streamlit UI, you’ll see a dropdown listing all indexed PDFs.
	•	Choose the document you want to query.

7. Running the Application
	1.	Activate your virtual environment (if not already active).
	2.	Launch Streamlit:

streamlit run app.py


	3.	Open the URL (e.g., http://localhost:8501) displayed in the terminal to access the app.

8. Usage Instructions
	1.	Upload PDF
	•	In the sidebar, use the “Upload a PDF Document” button.
	•	The script saves the file into doc/ and indexes it once.
	2.	Select & Query
	•	In “Step 2” within the app, select an indexed PDF from the dropdown.
	•	Enter your query text in the input box, then click “Search and Extract Text.”
	•	The RAG search retrieves a relevant page as an image, which is passed to the LLM for further analysis.
	3.	LLM Response
	•	The OpenAI API key in your .env is used to authenticate the model call.
	•	The returned text is displayed in the UI under “LLM Response.”

9. Troubleshooting
	•	Missing or Invalid OpenAI Key:
	•	Verify OPENAI_API_KEY is set in your .env.
	•	Double-check you have a valid subscription or usage limit.
	•	Indexing Issues:
	•	Ensure doc/ folder exists and the PDF is not locked or corrupted.
	•	If re-indexing the same PDF leads to conflicts, you may need to remove or overwrite the old index (depending on your library version).
	•	Dependencies:
	•	If you encounter import errors, confirm that all dependencies are listed in requirements.txt and installed.

10. Additional Notes
	•	Production Deployment:
	•	For heavier usage or remote access, consider deploying on a server (e.g., AWS, Azure, or Heroku) with proper secrets management.
	•	GPU Support:
	•	If you have a CUDA-enabled GPU, ensure you have the correct PyTorch build. Otherwise, the application will fall back to CPU or Apple Silicon acceleration (MPS).

Enjoy your Colpali-Based Multimodal RAG Application!